{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "from proxypool.error import PoolEmptyError\n",
    "from proxypool.setting import REDIS_HOST, REDIS_PORT, REDIS_PASSWORD, REDIS_KEY\n",
    "from proxypool.setting import MAX_SCORE, MIN_SCORE, INITIAL_SCORE\n",
    "from random import choice\n",
    "import re\n",
    "\n",
    "\n",
    "class RedisClient(object):\n",
    "    def __init__(self, host=REDIS_HOST, port=REDIS_PORT, password=REDIS_PASSWORD):\n",
    "        \"\"\"\n",
    "        初始化\n",
    "        :param host: Redis 地址\n",
    "        :param port: Redis 端口\n",
    "        :param password: Redis密码\n",
    "        \"\"\"\n",
    "        self.db = redis.StrictRedis(host=host, port=port, password=password, decode_responses=True)\n",
    "    \n",
    "    def add(self, proxy, score=INITIAL_SCORE):\n",
    "        \"\"\"\n",
    "        添加代理，设置分数为最高\n",
    "        :param proxy: 代理\n",
    "        :param score: 分数\n",
    "        :return: 添加结果\n",
    "        \"\"\"\n",
    "        if not re.match('\\d+\\.\\d+\\.\\d+\\.\\d+\\:\\d+', proxy):\n",
    "            print('代理不符合规范', proxy, '丢弃')\n",
    "            return\n",
    "        if not self.db.zscore(REDIS_KEY, proxy):\n",
    "            #return self.db.zadd(REDIS_KEY, score, proxy)\n",
    "            #更新为redis3.0+版本，解决redis3.0更新后的报错，如用旧版本还原上方代码\n",
    "            return self.db.zadd(REDIS_KEY, {proxy:score})\n",
    "    \n",
    "    def random(self):\n",
    "        \"\"\"\n",
    "        随机获取有效代理，首先尝试获取最高分数代理，如果不存在，按照排名获取，否则异常\n",
    "        :return: 随机代理\n",
    "        \"\"\"\n",
    "        result = self.db.zrangebyscore(REDIS_KEY, MAX_SCORE, MAX_SCORE)\n",
    "        if len(result):\n",
    "            return choice(result)\n",
    "        else:\n",
    "            result = self.db.zrevrange(REDIS_KEY, 0, 100)\n",
    "            if len(result):\n",
    "                return choice(result)\n",
    "            else:\n",
    "                raise PoolEmptyError\n",
    "    \n",
    "    def decrease(self, proxy):\n",
    "        \"\"\"\n",
    "        代理值减一分，小于最小值则删除\n",
    "        :param proxy: 代理\n",
    "        :return: 修改后的代理分数\n",
    "        \"\"\"\n",
    "        score = self.db.zscore(REDIS_KEY, proxy)\n",
    "        if score and score > MIN_SCORE:\n",
    "            print('代理', proxy, '当前分数', score, '减1')\n",
    "            #return self.db.zincrby(REDIS_KEY, proxy, -1)\n",
    "            #更新为redis3.0+版本，解决redis3.0更新后的报错，如用旧版本还原上方代码\n",
    "            return self.db.zincrby(REDIS_KEY, -1, proxy)\n",
    "        else:\n",
    "            print('代理', proxy, '当前分数', score, '移除')\n",
    "            return self.db.zrem(REDIS_KEY, proxy)\n",
    "    \n",
    "    def exists(self, proxy):\n",
    "        \"\"\"\n",
    "        判断是否存在\n",
    "        :param proxy: 代理\n",
    "        :return: 是否存在\n",
    "        \"\"\"\n",
    "        return not self.db.zscore(REDIS_KEY, proxy) == None\n",
    "    \n",
    "    def max(self, proxy):\n",
    "        \"\"\"\n",
    "        将代理设置为MAX_SCORE\n",
    "        :param proxy: 代理\n",
    "        :return: 设置结果\n",
    "        \"\"\"\n",
    "        print('代理', proxy, '可用，设置为', MAX_SCORE)\n",
    "        #return self.db.zadd(REDIS_KEY, MAX_SCORE, proxy)\n",
    "        #更新为redis3.0+版本，解决redis3.0更新后的报错，如用旧版本还原上方代码\n",
    "        return self.db.zadd(REDIS_KEY, {proxy:MAX_SCORE})\n",
    "    \n",
    "    def count(self):\n",
    "        \"\"\"\n",
    "        获取数量\n",
    "        :return: 数量\n",
    "        \"\"\"\n",
    "        return self.db.zcard(REDIS_KEY)\n",
    "    \n",
    "    def all(self):\n",
    "        \"\"\"\n",
    "        获取全部代理\n",
    "        :return: 全部代理列表\n",
    "        \"\"\"\n",
    "        return self.db.zrangebyscore(REDIS_KEY, MIN_SCORE, MAX_SCORE)\n",
    "    \n",
    "    def batch(self, start, stop):\n",
    "        \"\"\"\n",
    "        批量获取\n",
    "        :param start: 开始索引\n",
    "        :param stop: 结束索引\n",
    "        :return: 代理列表\n",
    "        \"\"\"\n",
    "        return self.db.zrevrange(REDIS_KEY, start, stop - 1)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    conn = RedisClient()\n",
    "    result = conn.batch(680, 688)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=RedisClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from proxypool.utils import get_page\n",
    "from pyquery import PyQuery as pq\n",
    "\n",
    "\n",
    "class ProxyMetaclass(type):\n",
    "    def __new__(cls, name, bases, attrs):\n",
    "        count = 0\n",
    "        attrs['__CrawlFunc__'] = []\n",
    "        for k, v in attrs.items():\n",
    "            if 'crawl_' in k:\n",
    "                attrs['__CrawlFunc__'].append(k)\n",
    "                count += 1\n",
    "        attrs['__CrawlFuncCount__'] = count\n",
    "        return type.__new__(cls, name, bases, attrs)\n",
    "\n",
    "\n",
    "class Crawler(object, metaclass=ProxyMetaclass):\n",
    "    def get_proxies(self, callback):\n",
    "        proxies = []\n",
    "        for proxy in eval(\"self.{}()\".format(callback)):\n",
    "            print('成功获取到代理', proxy)\n",
    "            proxies.append(proxy)\n",
    "        return proxies\n",
    "       \n",
    "    def crawl_daili66(self, page_count=4):\n",
    "        \"\"\"\n",
    "        获取代理66\n",
    "        :param page_count: 页码\n",
    "        :return: 代理\n",
    "        \"\"\"\n",
    "        start_url = 'http://www.66ip.cn/{}.html'\n",
    "        urls = [start_url.format(page) for page in range(1, page_count + 1)]\n",
    "        for url in urls:\n",
    "            print('Crawling', url)\n",
    "            html = get_page(url)\n",
    "            if html:\n",
    "                doc = pq(html)\n",
    "                trs = doc('.containerbox table tr:gt(0)').items()\n",
    "                for tr in trs:\n",
    "                    ip = tr.find('td:nth-child(1)').text()\n",
    "                    port = tr.find('td:nth-child(2)').text()\n",
    "                    yield ':'.join([ip, port])\n",
    "\n",
    "    def crawl_ip3366(self):\n",
    "        for page in range(1, 4):\n",
    "            start_url = 'http://www.ip3366.net/free/?stype=1&page={}'.format(page)\n",
    "            html = get_page(start_url)\n",
    "            ip_address = re.compile('<tr>\\s*<td>(.*?)</td>\\s*<td>(.*?)</td>')\n",
    "            # \\s * 匹配空格，起到换行作用\n",
    "            re_ip_address = ip_address.findall(html)\n",
    "            for address, port in re_ip_address:\n",
    "                result = address+':'+ port\n",
    "                yield result.replace(' ', '')\n",
    "    \n",
    "    def crawl_kuaidaili(self):\n",
    "        for i in range(1, 4):\n",
    "            start_url = 'http://www.kuaidaili.com/free/inha/{}/'.format(i)\n",
    "            html = get_page(start_url)\n",
    "            if html:\n",
    "                ip_address = re.compile('<td data-title=\"IP\">(.*?)</td>') \n",
    "                re_ip_address = ip_address.findall(html)\n",
    "                port = re.compile('<td data-title=\"PORT\">(.*?)</td>')\n",
    "                re_port = port.findall(html)\n",
    "                for address,port in zip(re_ip_address, re_port):\n",
    "                    address_port = address+':'+port\n",
    "                    yield address_port.replace(' ','')\n",
    "\n",
    "    def crawl_xicidaili(self):\n",
    "        for i in range(1, 3):\n",
    "            start_url = 'http://www.xicidaili.com/nn/{}'.format(i)\n",
    "            headers = {\n",
    "                'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "                'Cookie':'_free_proxy_session=BAh7B0kiD3Nlc3Npb25faWQGOgZFVEkiJWRjYzc5MmM1MTBiMDMzYTUzNTZjNzA4NjBhNWRjZjliBjsAVEkiEF9jc3JmX3Rva2VuBjsARkkiMUp6S2tXT3g5a0FCT01ndzlmWWZqRVJNek1WanRuUDBCbTJUN21GMTBKd3M9BjsARg%3D%3D--2a69429cb2115c6a0cc9a86e0ebe2800c0d471b3',\n",
    "                'Host':'www.xicidaili.com',\n",
    "                'Referer':'http://www.xicidaili.com/nn/3',\n",
    "                'Upgrade-Insecure-Requests':'1',\n",
    "            }\n",
    "            html = get_page(start_url, options=headers)\n",
    "            if html:\n",
    "                find_trs = re.compile('<tr class.*?>(.*?)</tr>', re.S)\n",
    "                trs = find_trs.findall(html)\n",
    "                for tr in trs:\n",
    "                    find_ip = re.compile('<td>(\\d+\\.\\d+\\.\\d+\\.\\d+)</td>') \n",
    "                    re_ip_address = find_ip.findall(tr)\n",
    "                    find_port = re.compile('<td>(\\d+)</td>')\n",
    "                    re_port = find_port.findall(tr)\n",
    "                    for address,port in zip(re_ip_address, re_port):\n",
    "                        address_port = address+':'+port\n",
    "                        yield address_port.replace(' ','')\n",
    "    \n",
    "    def crawl_ip3366(self):\n",
    "        for i in range(1, 4):\n",
    "            start_url = 'http://www.ip3366.net/?stype=1&page={}'.format(i)\n",
    "            html = get_page(start_url)\n",
    "            if html:\n",
    "                find_tr = re.compile('<tr>(.*?)</tr>', re.S)\n",
    "                trs = find_tr.findall(html)\n",
    "                for s in range(1, len(trs)):\n",
    "                    find_ip = re.compile('<td>(\\d+\\.\\d+\\.\\d+\\.\\d+)</td>')\n",
    "                    re_ip_address = find_ip.findall(trs[s])\n",
    "                    find_port = re.compile('<td>(\\d+)</td>')\n",
    "                    re_port = find_port.findall(trs[s])\n",
    "                    for address,port in zip(re_ip_address, re_port):\n",
    "                        address_port = address+':'+port\n",
    "                        yield address_port.replace(' ','')\n",
    "    \n",
    "    def crawl_iphai(self):\n",
    "        start_url = 'http://www.iphai.com/'\n",
    "        html = get_page(start_url)\n",
    "        if html:\n",
    "            find_tr = re.compile('<tr>(.*?)</tr>', re.S)\n",
    "            trs = find_tr.findall(html)\n",
    "            for s in range(1, len(trs)):\n",
    "                find_ip = re.compile('<td>\\s+(\\d+\\.\\d+\\.\\d+\\.\\d+)\\s+</td>', re.S)\n",
    "                re_ip_address = find_ip.findall(trs[s])\n",
    "                find_port = re.compile('<td>\\s+(\\d+)\\s+</td>', re.S)\n",
    "                re_port = find_port.findall(trs[s])\n",
    "                for address,port in zip(re_ip_address, re_port):\n",
    "                    address_port = address+':'+port\n",
    "                    yield address_port.replace(' ','')\n",
    "\n",
    "    def crawl_data5u(self):\n",
    "        start_url = 'http://www.data5u.com/free/gngn/index.shtml'\n",
    "        headers = {\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Accept-Language': 'en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7',\n",
    "            'Cache-Control': 'max-age=0',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Cookie': 'JSESSIONID=47AA0C887112A2D83EE040405F837A86',\n",
    "            'Host': 'www.data5u.com',\n",
    "            'Referer': 'http://www.data5u.com/free/index.shtml',\n",
    "            'Upgrade-Insecure-Requests': '1',\n",
    "            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.108 Safari/537.36',\n",
    "        }\n",
    "        html = get_page(start_url, options=headers)\n",
    "        if html:\n",
    "            ip_address = re.compile('<span><li>(\\d+\\.\\d+\\.\\d+\\.\\d+)</li>.*?<li class=\\\"port.*?>(\\d+)</li>', re.S)\n",
    "            re_ip_address = ip_address.findall(html)\n",
    "            for address, port in re_ip_address:\n",
    "                result = address + ':' + port\n",
    "                yield result.replace(' ', '')\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from proxypool.setting import *\n",
    "import sys\n",
    "\n",
    "class Getter():\n",
    "    def __init__(self):\n",
    "        self.redis = RedisClient()\n",
    "        self.crawler = Crawler()\n",
    "    \n",
    "    def is_over_threshold(self):\n",
    "        \"\"\"\n",
    "        判断是否达到了代理池限制\n",
    "        \"\"\"\n",
    "        if self.redis.count() >= POOL_UPPER_THRESHOLD:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def run(self):\n",
    "        print('获取器开始执行')\n",
    "        if not self.is_over_threshold():\n",
    "            for callback_label in range(self.crawler.__CrawlFuncCount__):\n",
    "                callback = self.crawler.__CrawlFunc__[callback_label]\n",
    "                # 获取代理\n",
    "                proxies = self.crawler.get_proxies(callback)\n",
    "                sys.stdout.flush()\n",
    "                for proxy in proxies:\n",
    "                    self.redis.add(proxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import time\n",
    "import sys\n",
    "try:\n",
    "    from aiohttp import ClientError\n",
    "except:\n",
    "    from aiohttp import ClientProxyConnectionError as ProxyConnectionError\n",
    "\n",
    "from proxypool.setting import *\n",
    "\n",
    "\n",
    "class Tester(object):\n",
    "    def __init__(self):\n",
    "        self.redis = RedisClient()\n",
    "    \n",
    "    async def test_single_proxy(self, proxy):\n",
    "        \"\"\"\n",
    "        测试单个代理\n",
    "        :param proxy:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        conn = aiohttp.TCPConnector(verify_ssl=False)\n",
    "        async with aiohttp.ClientSession(connector=conn) as session:\n",
    "            try:\n",
    "                if isinstance(proxy, bytes):\n",
    "                    proxy = proxy.decode('utf-8')\n",
    "                real_proxy = 'http://' + proxy\n",
    "                print('正在测试', proxy)\n",
    "                async with session.get(TEST_URL, proxy=real_proxy, timeout=15, allow_redirects=False) as response:\n",
    "                    if response.status in VALID_STATUS_CODES:\n",
    "                        self.redis.max(proxy)\n",
    "                        print('代理可用', proxy)\n",
    "                    else:\n",
    "                        self.redis.decrease(proxy)\n",
    "                        print('请求响应码不合法 ', response.status, 'IP', proxy)\n",
    "            except (ClientError, aiohttp.client_exceptions.ClientConnectorError, asyncio.TimeoutError, AttributeError):\n",
    "                self.redis.decrease(proxy)\n",
    "                print('代理请求失败', proxy)\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        测试主函数\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        print('测试器开始运行')\n",
    "        try:\n",
    "            count = self.redis.count()\n",
    "            print('当前剩余', count, '个代理')\n",
    "            for i in range(0, count, BATCH_TEST_SIZE):\n",
    "                start = i\n",
    "                stop = min(i + BATCH_TEST_SIZE, count)\n",
    "                print('正在测试第', start + 1, '-', stop, '个代理')\n",
    "                test_proxies = self.redis.batch(start, stop)\n",
    "                loop = asyncio.get_event_loop()\n",
    "                tasks = [self.test_single_proxy(proxy) for proxy in test_proxies]\n",
    "                loop.run_until_complete(asyncio.wait(tasks))\n",
    "                sys.stdout.flush()\n",
    "                time.sleep(5)\n",
    "        except Exception as e:\n",
    "            print('测试器发生错误', e.args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, g\n",
    "\n",
    "__all__ = ['app']\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "def get_conn():\n",
    "    if not hasattr(g, 'redis'):\n",
    "        g.redis = RedisClient()\n",
    "    return g.redis\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return '<h2>Welcome to Proxy Pool System</h2>'\n",
    "\n",
    "\n",
    "@app.route('/random')\n",
    "def get_proxy():\n",
    "    \"\"\"\n",
    "    Get a proxy\n",
    "    :return: 随机代理\n",
    "    \"\"\"\n",
    "    conn = get_conn()\n",
    "    return conn.random()\n",
    "\n",
    "\n",
    "@app.route('/count')\n",
    "def get_counts():\n",
    "    \"\"\"\n",
    "    Get the count of proxies\n",
    "    :return: 代理池总量\n",
    "    \"\"\"\n",
    "    conn = get_conn()\n",
    "    return str(conn.count())\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from multiprocessing import Process\n",
    "\n",
    "from proxypool.setting import *\n",
    "\n",
    "\n",
    "class Scheduler():\n",
    "    def schedule_tester(self, cycle=TESTER_CYCLE):\n",
    "        \"\"\"\n",
    "        定时测试代理\n",
    "        \"\"\"\n",
    "        tester = Tester()\n",
    "        while True:\n",
    "            print('测试器开始运行')\n",
    "            tester.run()\n",
    "            time.sleep(cycle)\n",
    "    \n",
    "    def schedule_getter(self, cycle=GETTER_CYCLE):\n",
    "        \"\"\"\n",
    "        定时获取代理\n",
    "        \"\"\"\n",
    "        getter = Getter()\n",
    "        while True:\n",
    "            print('开始抓取代理')\n",
    "            getter.run()\n",
    "            time.sleep(cycle)\n",
    "    \n",
    "    def schedule_api(self):\n",
    "        \"\"\"\n",
    "        开启API\n",
    "        \"\"\"\n",
    "        app.run(API_HOST, API_PORT)\n",
    "    \n",
    "    def run(self):\n",
    "        print('代理池开始运行')\n",
    "        \n",
    "        if TESTER_ENABLED:\n",
    "            self.schedule_tester()\n",
    "         \n",
    "        \n",
    "        if GETTER_ENABLED:\n",
    "            self.schedule_getter()\n",
    "           \n",
    "        \n",
    "        if API_ENABLED:\n",
    "            self.schedule_api()\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    try:\n",
    "        s = Scheduler()\n",
    "        s.run()\n",
    "    except:\n",
    "        main()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
